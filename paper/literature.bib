@online{mnistImage,
  author       = {Suvanjanprasi},
  title        = {MNIST dataset example},
  year         = {2024},
  date         = {2024-12-02},
  url          = {https://commons.wikimedia.org/wiki/File:MNIST_dataset_example.png},
  note         = {Image licensed under CC BY-SA 4.0 via Wikimedia Commons},
  organization = {Wikimedia Commons}
}

@article{zhou2018dorefa,
  title={DoReFa-Net: Training Low Bitwidth Convolutional Neural Networks with Low Bitwidth Gradients},
  author={Zhou, Shuchang and Ni, Zekun and Zhou, Xinyu and Wen, He and Wu, Yuxin},
  journal={arXiv preprint arXiv:1606.06160v3},
  year={2018}
}

@inproceedings{NEURIPS2018_335d3d1c,
 author = {Wang, Naigang and Choi, Jungwook and Brand, Daniel and Chen, Chia-Yu and Gopalakrishnan, Kailash},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Training Deep Neural Networks with 8-bit Floating Point Numbers},
 url = {https://proceedings.neurips.cc/paper_files/paper/2018/file/335d3d1cd7ef05ec77714a215134914c-Paper.pdf},
 volume = {31},
 year = {2018}
}

@inproceedings{shen2020qbert,
  title={Q-BERT: Hessian Based Ultra Low Precision Quantization of BERT},
  author={Shen, Shaojie and Dong, Zhen and Ye, Zhewei and Ma, Linjian and Tang, Jie and Wang, Zhangyang and Han, Song},
  booktitle={AAAI Conference on Artificial Intelligence},
  year={2020}
}

@article{frantar2022gptq,
  title={GPTQ: Accurate Post-training Quantization for Generative Pretrained Transformers},
  author={Frantar, Elias and Hubis, Filip and Alistarh, Dan},
  journal={arXiv preprint arXiv:2210.17323v2},
  year={2023}
}


@InProceedings{xiao2024smoothquant,
  title = 	 {{S}mooth{Q}uant: Accurate and Efficient Post-Training Quantization for Large Language Models},
  author =       {Xiao, Guangxuan and Lin, Ji and Seznec, Mickael and Wu, Hao and Demouth, Julien and Han, Song},
  booktitle = 	 {Proceedings of the 40th International Conference on Machine Learning},
  pages = 	 {38087--38099},
  year = 	 {2023},
  editor = 	 {Krause, Andreas and Brunskill, Emma and Cho, Kyunghyun and Engelhardt, Barbara and Sabato, Sivan and Scarlett, Jonathan},
  volume = 	 {202},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {23--29 Jul},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v202/xiao23c/xiao23c.pdf},
  url = 	 {https://proceedings.mlr.press/v202/xiao23c.html},
}

@online{fparithmetic,
  author  = {{Wikipedia contributors}},
  title   = {Floating-point arithmetic},
  year    = 2025,
  url     = {https://en.wikipedia.org/wiki/Floating-point_arithmetic},
  note    = {Accessed 15 July 2025}
}

@book {
    Russel2020,
    title = {Artificial Intelligence: A Modern Approach},
    author = {Russel, Stuart and Norvig, Peter},
    edition = 4,
    publisher = {Pearson},
    year = 2020,
    isbn = {978-0134610993}
}






%Alle verwendeten Quellen:
@inproceedings{jacob2018quantization,
  title={Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference},
  author={Jacob, Benoit and Kligys, Skirmantas and Chen, Bo and Zhu, Menglong and Tang, Matthew and Howard, Andrew and Adam, Hartwig and Kalenichenko, Dmitry},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2018}
}
@inproceedings{rastegariECCV16,
  Author={Mohammad Rastegari and Vicente Ordonez and Joseph Redmon and Ali Farhadi},
  Title={XNOR-Net: ImageNet Classification Using Binary Convolutional Neural Networks},
  Booktitle={ECCV},
  Year={2016}
}
@inproceedings{micikevicius2017mixed,
  title={Mixed precision training},
  author={Micikevicius, Paulius and Narang, Sharan and Alben, Jonah and Diamos, Greg and Elsen, Erich and Garcia, David and Ginsburg, Boris and Houston, Michael and Kuchaiev, Oleksii and Venkatesh, Ganesh and Wu, Hao},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2018}
}