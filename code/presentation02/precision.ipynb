{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Subset\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kept the following code block for reference. We don't use `torch.quantization` - no quantization in general. With quantization, we could go very low in precision (e.g., int8), see [DoReFa](https://arxiv.org/pdf/1606.06160), for example.\n",
    "\n",
    "We also don't use [Automatic Mixed Precision](https://pytorch.org/docs/stable/amp.html).\n",
    "\n",
    "For now, we just go from float64 down to float16 as a first step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Supported engines:\", torch.backends.quantized.supported_engines)\n",
    "print(\"Currently active quantized engine:\", torch.backends.quantized.engine)\n",
    "torch.backends.quantized.engine = \"qnnpack\"\n",
    "print(\"Now active quantized engine:\", torch.backends.quantized.engine)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 3\n",
    "K_FOLDS = 5\n",
    "MOMENTUM = 0.9\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_REATE = 0.01\n",
    "DTYPES = [torch.float64, torch.float32, torch.float16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Linear layers & ReLU are separate for fusing when quantizing (if someone wants to implement that)\n",
    "        # MNIST => 28x28=784\n",
    "        # Linear = fully connected, y=xA^T+b\n",
    "        # ReLU = activation for non-linearity\n",
    "        # Output is 10 logits (\"logit\" = raw output of a linear layer = pre-activation) used later with CrossEntropyLoss\n",
    "        self.fc1 = nn.Linear(784, 128)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 28x28 MNIST images are flattened into 784-dim vectors\n",
    "        x = x.view(x.size(0), -1)  # [batchSize,1,28,28] to [batchSize,784]\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def trainEpoch(model, loader, criterion, optimizer, device=\"cpu\", dtype=torch.float32):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in loader:\n",
    "\n",
    "        images = images.to(device, dtype=dtype)  # Adapt input data to precision\n",
    "        labels = labels.to(device)  # Labels stay as integer type (LongTensor)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    return running_loss / len(loader)\n",
    "\n",
    "\n",
    "def evaluate(model, loader, device=\"cpu\", dtype=torch.float32):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images = images.to(device, dtype=dtype)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = outputs.max(dim=1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return 100.0 * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/63746182/correct-way-of-normalizing-and-scaling-the-mnist-dataset\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,)),\n",
    "    ]\n",
    ")\n",
    "full_dataset = torchvision.datasets.MNIST(\n",
    "    root=\"./data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform,\n",
    ")\n",
    "train_set = torchvision.datasets.MNIST(\n",
    "    root=\"./data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform,\n",
    ")\n",
    "val_set = torchvision.datasets.MNIST(\n",
    "    root=\"./data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform,\n",
    ")\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_set,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    ")\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_set,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training from scratch with decreasing precision\n",
    "\n",
    "This should answer the question: _How does changing the precision during training affect the final modelâ€™s accuracy and performance?_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_size = len(full_dataset) // K_FOLDS\n",
    "indices = list(range(len(full_dataset)))\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "results = {}\n",
    "timings = {}\n",
    "\n",
    "for current_dtype in DTYPES:\n",
    "    print(\"\\n==============================================\")\n",
    "    print(f\"Training with dtype = {current_dtype}\")\n",
    "    fold_accuracies = []\n",
    "    train_times = []\n",
    "    eval_times = []\n",
    "\n",
    "    for fold in range(K_FOLDS):\n",
    "        print(f\"\\n--- Fold {fold+1}/{K_FOLDS} ---\")\n",
    "\n",
    "        val_indices = indices[fold * fold_size : (fold + 1) * fold_size]\n",
    "        train_indices = indices[: fold * fold_size] + indices[(fold + 1) * fold_size :]\n",
    "\n",
    "        train_subset = Subset(full_dataset, train_indices)\n",
    "        val_subset = Subset(full_dataset, val_indices)\n",
    "\n",
    "        train_loader = torch.utils.data.DataLoader(\n",
    "            train_subset, batch_size=BATCH_SIZE, shuffle=True\n",
    "        )\n",
    "        val_loader = torch.utils.data.DataLoader(\n",
    "            val_subset, batch_size=BATCH_SIZE, shuffle=False\n",
    "        )\n",
    "\n",
    "        model = MLP().to(device, dtype=current_dtype)\n",
    "        # Same dtype necessary here for CrossEntropyLoss? (I mean it is a subclasses of nn.Module so...)\n",
    "        criterion = nn.CrossEntropyLoss().to(device, dtype=current_dtype)\n",
    "        optimizer = optim.SGD(model.parameters(), lr=LEARNING_REATE, momentum=MOMENTUM)\n",
    "\n",
    "        train_start = time.time()\n",
    "        for epoch in range(EPOCHS):\n",
    "            loss_val = trainEpoch(\n",
    "                model,\n",
    "                train_loader,\n",
    "                criterion,\n",
    "                optimizer,\n",
    "                device=device,\n",
    "                dtype=current_dtype,\n",
    "            )\n",
    "            acc_val = evaluate(model, val_loader, device=device, dtype=current_dtype)\n",
    "            print(\n",
    "                f\"Epoch {epoch+1}/{EPOCHS}, Loss: {loss_val:.4f}, Val Acc: {acc_val:.2f}%\"\n",
    "            )\n",
    "        train_end = time.time()\n",
    "        train_duration = train_end - train_start\n",
    "        train_times.append(train_duration)\n",
    "\n",
    "        eval_start = time.time()\n",
    "        final_acc = evaluate(model, val_loader, device=device, dtype=current_dtype)\n",
    "        eval_end = time.time()\n",
    "        eval_duration = eval_end - eval_start\n",
    "        eval_times.append(eval_duration)\n",
    "\n",
    "        fold_accuracies.append(final_acc)\n",
    "        print(f\"Fold {fold+1} accuracy: {final_acc:.2f}%\")\n",
    "        print(\n",
    "            f\"Training time: {train_duration:.2f}s | Inference time: {eval_duration:.2f}s\"\n",
    "        )\n",
    "\n",
    "    avg_acc = sum(fold_accuracies) / K_FOLDS\n",
    "    avg_train_time = sum(train_times) / K_FOLDS\n",
    "    avg_eval_time = sum(eval_times) / K_FOLDS\n",
    "\n",
    "    results[str(current_dtype)] = avg_acc\n",
    "    timings[str(current_dtype)] = {\n",
    "        \"avg_train_time\": avg_train_time,\n",
    "        \"avg_eval_time\": avg_eval_time,\n",
    "    }\n",
    "\n",
    "print(\"\\nAveraged results over 5 folds:\")\n",
    "for dtype_str, acc_val in results.items():\n",
    "    print(f\"{dtype_str}: {acc_val:.2f}%\")\n",
    "\n",
    "print(\"\\nAverage timing per dtype:\")\n",
    "for dtype_str, t in timings.items():\n",
    "    print(\n",
    "        f\"{dtype_str}: Train = {t['avg_train_time']:.2f}s, Eval = {t['avg_eval_time']:.2f}s\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    \"float64\": 96.82,\n",
    "    \"float32\": 96.76,\n",
    "    \"float16\": 96.74,\n",
    "}\n",
    "df = pd.DataFrame(list(results.items()), columns=[\"Precision\", \"Accuracy\"])\n",
    "plt.figure(figsize=(8, 5), dpi=300)\n",
    "plt.bar(df[\"Precision\"], df[\"Accuracy\"], color=\"#b9a4c6\")\n",
    "plt.title(\"Model Accuracies (Training and Inference)\")\n",
    "plt.xlabel(\"Precision Type\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.ylim(96.5, 97)\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timings = {\n",
    "    \"torch.float64\": {\"Train\": 17.92, \"Eval\": 1.13},\n",
    "    \"torch.float32\": {\"Train\": 17.20, \"Eval\": 1.05},\n",
    "    \"torch.float16\": {\"Train\": 17.88, \"Eval\": 1.14},\n",
    "}\n",
    "timing_df = pd.DataFrame(timings).T.reset_index().rename(columns={\"index\": \"Precision\"})\n",
    "timing_df = timing_df[[\"Precision\", \"Train\", \"Eval\"]]\n",
    "x = range(len(timing_df))\n",
    "width = 0.35\n",
    "plt.figure(figsize=(9, 5), dpi=300)\n",
    "plt.bar(\n",
    "    [i - width / 2 for i in x],\n",
    "    timing_df[\"Train\"],\n",
    "    width=width,\n",
    "    label=\"Train Time\",\n",
    "    color=\"#b9a4c6\",\n",
    ")\n",
    "plt.bar(\n",
    "    [i + width / 2 for i in x],\n",
    "    timing_df[\"Eval\"],\n",
    "    width=width,\n",
    "    label=\"Eval Time\",\n",
    "    color=\"#d2bfd8\",\n",
    ")\n",
    "plt.xticks(x, timing_df[\"Precision\"])\n",
    "plt.title(\"Average Training and Inference Times\")\n",
    "plt.xlabel(\"Precision Type\")\n",
    "plt.ylabel(\"Time (sec)\")\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on single (high) precision and test lower-precision inference effects (= inference-only testing)\n",
    "\n",
    "This should show the effect of precision during inference after training a single model.\n",
    "\n",
    "So the model is trained with float64 and then a **post-training precision reduction** is done.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    \"float64\": [],\n",
    "    \"float32_eval_only\": [],\n",
    "    \"float16_eval_only\": [],\n",
    "}\n",
    "\n",
    "for fold in range(K_FOLDS):\n",
    "    print(f\"\\n==============================================\")\n",
    "    print(f\"Training Fold {fold+1}/{K_FOLDS} with dtype = float64\")\n",
    "\n",
    "    val_indices = indices[fold * fold_size : (fold + 1) * fold_size]\n",
    "    train_indices = indices[: fold * fold_size] + indices[(fold + 1) * fold_size :]\n",
    "\n",
    "    train_subset = Subset(full_dataset, train_indices)\n",
    "    val_subset = Subset(full_dataset, val_indices)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_subset, batch_size=BATCH_SIZE, shuffle=True\n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_subset, batch_size=BATCH_SIZE, shuffle=False\n",
    "    )\n",
    "\n",
    "    model = MLP().to(device, dtype=torch.float64)  # float64 only\n",
    "    criterion = nn.CrossEntropyLoss().to(device, dtype=torch.float64)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=LEARNING_REATE, momentum=MOMENTUM)\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        loss_val = trainEpoch(\n",
    "            model,\n",
    "            train_loader,\n",
    "            criterion,\n",
    "            optimizer,\n",
    "            device=device,\n",
    "            dtype=torch.float64,\n",
    "        )\n",
    "        acc_val = evaluate(model, val_loader, device=device, dtype=torch.float64)\n",
    "        print(\n",
    "            f\"Epoch {epoch+1}/{EPOCHS}, Loss: {loss_val:.4f}, Val Acc: {acc_val:.2f}%\"\n",
    "        )\n",
    "\n",
    "    # float64 eval\n",
    "    acc_float64 = evaluate(model, val_loader, device=device, dtype=torch.float64)\n",
    "    results[\"float64\"].append(acc_float64)\n",
    "    print(f\"Fold {fold+1} accuracy (float64): {acc_float64:.2f}%\")\n",
    "\n",
    "    ################################################################################\n",
    "\n",
    "    # Eval-only with float32\n",
    "    model_float32 = model.to(dtype=torch.float32)\n",
    "    acc_float32 = evaluate(\n",
    "        model_float32, val_loader, device=device, dtype=torch.float32\n",
    "    )\n",
    "    results[\"float32_eval_only\"].append(acc_float32)\n",
    "    print(f\"Fold {fold+1} accuracy (eval only, float32): {acc_float32:.2f}%\")\n",
    "\n",
    "    ################################################################################\n",
    "\n",
    "    # Eval-only with float16\n",
    "    model_float16 = model.to(dtype=torch.float16)\n",
    "    acc_float16 = evaluate(\n",
    "        model_float16, val_loader, device=device, dtype=torch.float16\n",
    "    )\n",
    "    results[\"float16_eval_only\"].append(acc_float16)\n",
    "    print(f\"Fold {fold+1} accuracy (eval only, float16): {acc_float16:.2f}%\")\n",
    "\n",
    "\n",
    "print(\"\\nAveraged results over 5 folds:\")\n",
    "for key in results:\n",
    "    avg = sum(results[key]) / K_FOLDS\n",
    "    print(f\"{key}: {avg:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    \"float64 (trained + eval)\": 96.77,\n",
    "    \"float32 (eval only)\": 96.77,\n",
    "    \"float16 (eval only)\": 96.77,\n",
    "}\n",
    "df = pd.DataFrame(list(results.items()), columns=[\"Precision\", \"Accuracy\"])\n",
    "plt.figure(figsize=(8, 5), dpi=300)\n",
    "plt.bar(df[\"Precision\"], df[\"Accuracy\"], color=\"#b9a4c6\")\n",
    "plt.title(\"Model Accuracies (Inference Only)\")\n",
    "plt.xlabel(\"Precision Type\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.ylim(96.5, 97)\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
